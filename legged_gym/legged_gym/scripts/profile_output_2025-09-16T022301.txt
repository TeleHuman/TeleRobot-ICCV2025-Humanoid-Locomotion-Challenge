Timer unit: 1e-09 s

Total time: 0.0441135 s
File: /home/lxz/ICCV2025-Challenge/legged_gym/legged_gym/envs/base/humanoid_robot.py
Function: reset_idx at line 398

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   398                                               @profile
   399                                               def reset_idx(self, env_ids):
   400                                                   """ Reset some environments.
   401                                                       Calls self._reset_dofs(env_ids), self._reset_root_states(env_ids), and self._resample_commands(env_ids)
   402                                                       [Optional] calls self._update_terrain_curriculum(env_ids), self.update_command_curriculum(env_ids) and
   403                                                       Logs episode info
   404                                                       Resets some buffers
   405                                           
   406                                                   Args:
   407                                                       env_ids (list[int]): List of environment ids which must be reset
   408                                                   """
   409         1       2376.0   2376.0      0.0          import time
   410         1       1066.0   1066.0      0.0          start_time = time.time()
   411         1       9295.0   9295.0      0.0          if len(env_ids) == 0:
   412                                                       return
   413                                                   
   414         1        705.0    705.0      0.0          if self.save:
   415                                                       for env_id in env_ids:
   416                                                           try:
   417                                                               if len(self.current_episode_buffer['observations'][env_id]) > 750:
   418                                                                   # 转换为numpy数组
   419                                                                   episode_obs = np.stack(self.current_episode_buffer['observations'][env_id])  # [T,*]
   420                                                                   episode_act = np.stack(self.current_episode_buffer['actions'][env_id])       # [T,*]
   421                                                                   episode_rew = np.stack(self.current_episode_buffer['rewards'][env_id])      # [T]
   422                                                                   episode_hei = np.stack(self.current_episode_buffer['height_map'][env_id])      # [T, 396]
   423                                                                   episode_body = np.stack(self.current_episode_buffer['rigid_body_state'][env_id]) # [T,13,13] first is root
   424                                                                   episode_dof = np.stack(self.current_episode_buffer['dof_state'][env_id])
   425                                                                 
   426                                                                   # 存入主数据存储
   427                                                                   self.episode_data['observations'][env_id].append(episode_obs)
   428                                                                   self.episode_data['actions'][env_id].append(episode_act)
   429                                                                   self.episode_data['rewards'][env_id].append(episode_rew)
   430                                                                   self.episode_data['height_map'][env_id].append(episode_hei)
   431                                                                   self.episode_data['rigid_body_state'][env_id].append(episode_body)
   432                                                                   self.episode_data['dof_state'][env_id].append(episode_dof)
   433                                           
   434                                                                   
   435                                                                   # 处理privileged观测
   436                                                                   if self.privileged_obs_buf is not None:
   437                                                                       episode_priv = np.stack(self.current_episode_buffer['privileged_obs'][env_id]) # [T,*]
   438                                                                       self.episode_data['privileged_obs'][env_id].append(episode_priv)
   439                                                                   
   440                                                                   # 清空当前buffer
   441                                                                   self.current_episode_buffer['observations'][env_id] = []
   442                                                                   self.current_episode_buffer['actions'][env_id] = []
   443                                                                   self.current_episode_buffer['rewards'][env_id] = []
   444                                                                   self.current_episode_buffer['height_map'][env_id] = []
   445                                                                   self.current_episode_buffer['privileged_obs'][env_id] = []
   446                                                                   self.current_episode_buffer['rigid_body_state'][env_id] = []
   447                                                                   self.current_episode_buffer['dof_state'][env_id] = []
   448                                                                   
   449                                                                   print(f"Env {env_id} have saved {episode_obs.shape[0]} step data")
   450                                                           except Exception as e:
   451                                                               print(f"An error occured when saving env {env_id}: {str(e)}")
   452                                                   
   453                                                   # update curriculum
   454         1       1363.0   1363.0      0.0          if self.cfg.terrain.curriculum:
   455                                                       self._update_terrain_curriculum(env_ids)
   456                                                   # avoid updating command curriculum at each step since the maximum command is common to all envs
   457         1       1490.0   1490.0      0.0          if self.cfg.commands.curriculum and (self.common_step_counter % self.max_episode_length==0):
   458                                                       self.update_command_curriculum(env_ids)
   459                                           
   460                                                   # reset robot states
   461         1    2530042.0 2.53e+06      5.7          self._reset_dofs(env_ids)
   462         1    1625844.0 1.63e+06      3.7          self._reset_root_states(env_ids)
   463         1     129691.0 129691.0      0.3          self._resample_commands(env_ids)
   464         1   10859863.0 1.09e+07     24.6          self.gym.simulate(self.sim)
   465         1    1460538.0 1.46e+06      3.3          self.gym.fetch_results(self.sim, True)
   466         1     945061.0 945061.0      2.1          self.gym.refresh_rigid_body_state_tensor(self.sim)
   467                                           
   468                                                   # reset buffers
   469         1     369371.0 369371.0      0.8          self.last_last_actions[env_ids] = 0.
   470         1     359845.0 359845.0      0.8          self.last_actions[env_ids] = 0.
   471         1     217654.0 217654.0      0.5          self.last_foot_action[env_ids] = 0.
   472         1     177753.0 177753.0      0.4          self.last_dof_vel[env_ids] = 0.
   473         1    2240438.0 2.24e+06      5.1          self.last_torques[env_ids] = 0.
   474         1      27507.0  27507.0      0.1          self.last_root_vel[:] = 0.
   475         1    1452257.0 1.45e+06      3.3          self.feet_air_time[env_ids] = 0.
   476         1     206800.0 206800.0      0.5          self.reset_buf[env_ids] = 1
   477         1    1245962.0 1.25e+06      2.8          self.obs_history_buf[env_ids, :, :] = 0.  # reset obs history buffer TODO no 0s
   478         1     140218.0 140218.0      0.3          self.contact_buf[env_ids, :, :] = 0.
   479         1    1154611.0 1.15e+06      2.6          self.action_history_buf[env_ids, :, :] = 0.
   480         1     339064.0 339064.0      0.8          self.cur_goal_idx[env_ids] = 0
   481         1     325374.0 325374.0      0.7          self.reach_goal_timer[env_ids] = 0
   482                                           
   483         1     166415.0 166415.0      0.4          self.phase_length_buf[env_ids] = 0 
   484                                           
   485                                                   # fill extras
   486         1       2000.0   2000.0      0.0          self.extras["episode"] = {}
   487        18       8892.0    494.0      0.0          for key in self.episode_sums.keys():
   488        17    4285938.0 252114.0      9.7              self.extras["episode"]['rew_' + key] = torch.mean(self.episode_sums[key][env_ids]) / self.max_episode_length_s
   489        17   13672074.0 804239.6     31.0              self.episode_sums[key][env_ids] = 0.
   490         1     143117.0 143117.0      0.3          self.episode_length_buf[env_ids] = 0
   491                                           
   492                                                   # log additional curriculum info
   493         1       2552.0   2552.0      0.0          if self.cfg.terrain.curriculum:
   494                                                       # print("terrain level = ", self.terrain_levels, " mean  ", torch.mean(self.terrain_levels.float()))
   495                                                       self.extras["episode"]["terrain_level"] = torch.mean(self.terrain_levels.float())
   496         1       1584.0   1584.0      0.0          if self.cfg.commands.curriculum:
   497                                                       self.extras["episode"]["max_command_x"] = self.command_ranges["lin_vel_x"][1]
   498                                                   # send timeout info to the algorithm
   499         1       3697.0   3697.0      0.0          if self.cfg.env.send_timeouts:
   500         1        758.0    758.0      0.0              self.extras["time_outs"] = self.time_out_buf
   501                                           
   502         1       2237.0   2237.0      0.0          end_time = time.time()
   503                                                   # print(f"Reset {len(env_ids)} envs, took {end_time - start_time:.3f} seconds")

Total time: 0.200005 s
File: /home/lxz/ICCV2025-Challenge/legged_gym/legged_gym/envs/base/humanoid_robot.py
Function: post_physics_step at line 299

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   299                                               @profile
   300                                               def post_physics_step(self):
   301                                                   """ check terminations, compute observations and rewards
   302                                                       calls self._post_physics_step_callback() for common computations 
   303                                                       calls self._draw_debug_vis() if needed
   304                                                   """
   305         1    1103289.0  1.1e+06      0.6          self.gym.refresh_actor_root_state_tensor(self.sim)
   306         1       7798.0   7798.0      0.0          self.gym.refresh_net_contact_force_tensor(self.sim)
   307         1     145505.0 145505.0      0.1          self.gym.refresh_rigid_body_state_tensor(self.sim)
   308                                                   # self.gym.refresh_force_sensor_tensor(self.sim)
   309                                           
   310         1      17865.0  17865.0      0.0          self.episode_length_buf += 1
   311         1       3488.0   3488.0      0.0          self.phase_length_buf += 1 
   312         1        961.0    961.0      0.0          self.common_step_counter += 1
   313                                           
   314                                                   # prepare quantities
   315         1      18561.0  18561.0      0.0          self.base_quat[:] = self.root_states[:, 3:7]
   316         1     139367.0 139367.0      0.1          self.base_lin_vel[:] = quat_rotate_inverse(self.base_quat, self.root_states[:, 7:10])
   317         1      31142.0  31142.0      0.0          self.base_ang_vel[:] = quat_rotate_inverse(self.base_quat, self.root_states[:, 10:13])
   318         1      26065.0  26065.0      0.0          self.projected_gravity[:] = quat_rotate_inverse(self.base_quat, self.gravity_vec)
   319         1      23930.0  23930.0      0.0          self.base_lin_acc = (self.root_states[:, 7:10] - self.last_root_vel[:, :3]) / self.dt
   320                                           
   321         1      18550.0  18550.0      0.0          self.knee_pos = self.rigid_body_states.view(self.num_envs, self.num_bodies, 13)[:, self.knee_indices, 0:3]
   322         1       8154.0   8154.0      0.0          self.feet_pos = self.rigid_body_states.view(self.num_envs, self.num_bodies, 13)[:, self.feet_indices, 0:3]
   323                                           
   324         1   12397499.0 1.24e+07      6.2          self.roll, self.pitch, self.yaw = euler_from_quaternion(self.base_quat)
   325                                           
   326         1    9992867.0 9.99e+06      5.0          contact = torch.norm(self.contact_forces[:, self.feet_indices], dim=-1) > 2.
   327         1    4077762.0 4.08e+06      2.0          self.contact_filt = torch.logical_or(contact, self.last_contacts) 
   328         1       4016.0   4016.0      0.0          self.last_contacts = contact
   329                                                   
   330                                                   # self._update_jump_schedule()
   331         1   22769655.0 2.28e+07     11.4          self._update_goals()
   332         1  149218656.0 1.49e+08     74.6          self._post_physics_step_callback()
   333                                           
   334                                                   # compute observations, rewards, resets, ...
   335                                                   self.check_termination()
   336                                                   self.compute_reward()
   337                                                   env_ids = self.reset_buf.nonzero(as_tuple=False).flatten()
   338                                                   self.reset_idx(env_ids)
   339                                           
   340                                                   self.cur_goals = self._gather_cur_goals()
   341                                                   self.next_goals = self._gather_cur_goals(future=1)
   342                                           
   343                                                   # self.update_depth_buffer()
   344                                           
   345                                                   self.compute_observations() # in some cases a simulation step might be required to refresh some obs (for example body positions)
   346                                           
   347                                                   self.last_last_actions[:] = self.last_actions[:]
   348                                                   self.last_actions[:] = self.actions[:]
   349                                                   self.last_dof_vel[:] = self.dof_vel[:]
   350                                                   self.last_torques[:] = self.torques[:]
   351                                                   self.last_root_vel[:] = self.root_states[:, 7:13]
   352                                                   if(self.time_stamp ==5):
   353                                                       self.last_foot_action = self.rigid_body_states[:, self.feet_indices, :]
   354                                                       self.time_stamp=0
   355                                                   else :
   356                                                       self.time_stamp=self.time_stamp+1
   357                                                   
   358                                                   if self.viewer and self.enable_viewer_sync and self.debug_viz:
   359                                                       self.gym.clear_lines(self.viewer)
   360                                                       # self._draw_height_samples()
   361                                                       self._draw_goals()
   362                                                       # self._draw_feet()
   363                                                       if self.cfg.depth.use_camera:
   364                                                           window_name = "Depth Image"
   365                                                           cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
   366                                                           cv2.imshow("Depth Image", self.depth_buffer[self.lookat_id, -1].cpu().numpy() + 0.5)
   367                                                           cv2.waitKey(1)
   368                                           
   369                                                   cur_knee_pos_trans = self.knee_pos - self.root_states[:, 0:3].unsqueeze(1)
   370                                                   for i in range(len(self.knee_indices)):
   371                                                       self.knee_pos_in_body[:, i, :] = quat_rotate_inverse(self.base_quat, cur_knee_pos_trans[:, i, :])
   372                                           
   373                                                   cur_feet_pos_trans = self.feet_pos - self.root_states[:, 0:3].unsqueeze(1)
   374                                                   for i in range(len(self.feet_indices)):
   375                                                       self.feet_pos_in_body[:, i, :] = quat_rotate_inverse(self.base_quat, cur_feet_pos_trans[:, i, :])

  0.04 seconds - /home/lxz/ICCV2025-Challenge/legged_gym/legged_gym/envs/base/humanoid_robot.py:398 - reset_idx
  0.20 seconds - /home/lxz/ICCV2025-Challenge/legged_gym/legged_gym/envs/base/humanoid_robot.py:299 - post_physics_step
